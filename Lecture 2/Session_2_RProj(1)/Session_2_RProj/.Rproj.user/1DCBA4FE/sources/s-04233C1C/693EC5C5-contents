#######################################
## Chapter 10 - Logistic Regression  ## 
#######################################

#NOTE: Prepared with R version 3.6.0

#set the working directory to appropriate folder on your machine, so as to access the data
#files.

#load the required librarie(s)/package(s) for this chapter
#Install the package(s) below once on your machine. To do so, uncomment the 
#install.packages line(s) below.

#install.packages("caret")
#install.packages("MASS")
#install.packages("glmulti")
#install.packages("rJava")
library(caret)
library(MASS)
library(glmulti)

## Problem 10.1 Financial Condition of Banks. 
##The file Banks.csv includes data on a sample of 20 banks. The "Financial 
##Condition" column records the judgment of an expert on the financial 
##condition of each bank. This outcome variable takes one of two possible 
##values-weak or strong-according to the financial condition of the bank. The
##predictors are two ratios used in the financial analysis of banks: 
##TotLns&Lses/Assets is the ratio of total loans and leases to total assets 
##and TotExp/Assets is the ratio of total expenses to total assets. The target 
##is to use the two ratios for classifying the financial condition of a new 
##bank.
##Run a logistic regression model (on the entire dataset) that models the 
##status of a bank as a function of the two financial measures provided. 
##Specify the success class as weak (this is similar to creating a dummy that 
##is 1 for financially weak banks and 0 otherwise), and use the default cutoff
##value of 0.5.

#load the data 
bank.df <- read.csv("banks.csv")

#fit logistic regression model and obtain the summary
reg<-glm(Financial.Condition ~ TotExp.Assets + TotLns.Lses.Assets, 
         data = bank.df, family = "binomial")
summary(reg)
#Coefficients:
#                   Estimate Std. Error z value Pr(>|z|)  
#(Intercept)         -14.721      6.675  -2.205   0.0274 *
#TotExp.Assets        89.834     47.781   1.880   0.0601 .
#TotLns.Lses.Assets    8.371      5.779   1.449   0.1474  

##10.1.a Write the estimated equation that associates the financial condition 
##of a bank with its two predictors in three formats:

##10.1.a.i The logit as a function of the predictors

# logit = -14.721 + (89.834 * TotExp.Assets) + (8.371 * TotLns.Lses.Assets)

##10.1.a.ii The odds as a function of the predictors

# Odds = e^(logit) = e^(-14.7207 + (89.8321 * TotExp/Assets) + 
#                       (8.3712 * TotLns&Lses/Assets)

##10.1.a.iii The probability as a function of the predictors

# p = (1 + Exp[-(-14.7207 + (89.8321 * TotExp/Assets) + 
#         (8.3712 * TotLns&Lses/Assets)])^-1

##10.1.b Consider a new bank whose total loans and leases/assets ratio = 0.6 
##and total expenses/assets ratio = 0.11. From your logistic regression model, 
##estimate the following four quantities for this bank (use R to do all the 
##intermediate calculations; show your final answers to four decimal places): 
##the logit, the odds, the probability of being financially weak, and the 
##classification of the bank (use cutoff = 0.5).

# new record
logit <- c(1, 0.11, 0.6) %*% reg$coefficients
odds <- exp(-logit)
prob <- 1/(1+odds)
prob
#> prob
#          [,1]
#[1,] 0.5457504

#probability that the new bank is 0.5457 and therefore the predicted class 
#for this new bank is 1, or "financially week".

##10.1.c The cutoff value of 0.5 is used in conjunction with the probability of
##being financially weak. Compute the threshold that should be used if we want
##to make a classification based on the odds of being financially weak, and 
##the threshold for the corresponding logit.

#Cutoff value of p=0.5.
#Odds = (p) / (1-p) = (0.5) / (1-0.5) = 1
#If odds > 1 then classify financial status as "weak" (otherwise classify as 
#"strong").
#Logit = ln (odds) = ln (1) = 0
#If Logit > 0 then classify financial status as "weak" (otherwise, classify it 
#as "strong")
#Therefore, a cutoff of 0.5 on the probability of being weak is equivalent to a 
#threshold of 1 on the odds of being weak, and to a threshold of 0 on the logit.

##10.1.d Interpret the estimated coefficient for the total loans & leases to 
##total assets ratio (TotLns&Lses/Assets) in terms of the odds of being 
##financially weak.

#A positive coefficient in the logit model translates into a coefficient larger 
#than 1 in the odds model.
#In the logit model, the estimated coefficient for total expenses-to-assets 
#ratio is 8.37. In the odds models, the coefficient is e^8.37 = 4316. This 
#means that an increase of a unit in total loans and leases-to-assets is 
#associated with an increase in the odds of being financially weak by a factor 
#of 4321.

##10.1.e When a bank that is in poor financial condition is misclassified as 
##financially strong, the misclassification cost is much higher than when a 
##financially strong bank is misclassified as weak. To minimize the expected 
##cost of misclassification, should the cutoff value for classification 
##(which is currently at 0.5) be increased or decreased?

#In order to minimize the expected cost of misclassification in this case, 
#we need to decrease the cutoff.

#############################

## Problem 10.2 Identifying Good System Administrators. 
##A management consultant is studying the roles played by experience and 
##training in a system administrator's ability to complete a set of tasks in a 
##specified amount of time. In particular, she is interested in discriminating
##between administrators who are able to complete given tasks within a 
##specified time and those who are not. Data are collected on the performance
##of 75 randomly selected administrators. They are stored in the file 
##SystemAdministrators.csv.
##The variable Experience measures months of full-time system administrator 
##experience, while Training measures the number of relevant training credits.
##The outcome variable Completed is either Yes or No, according to whether or 
##not the administrator completed the tasks.

#load the data 
admin.df <- read.csv("SystemAdministrators.csv")
t(t(names(admin.df)))

##10.2.a Create a scatter plot of Experience vs. Training using color or symbol
##to distinguish programmers who completed the task from those who did not 
##complete it. Which predictor(s) appear(s) potentially useful for classifying 
##task completion?

plot(Experience ~ Training, data = admin.df, col = (admin.df$Completed.task == "Yes")+1)

#From the scatterplot we can observe that programmers who completed the task 
#tend to have more experience. Training, however, does not play much a role in 
#task completion. Therefore, the predictor Experience appears more useful for 
#classifying task completion.

##10.2.b Run a logistic regression model with both predictors using the entire
##dataset as training data. Among those who completed the task, what is the
##percentage of programmers incorrectly classified as failing to complete the 
##task?

#fit the model and obtain the model summary
reg<-glm(Completed.task ~ ., data = admin.df, family = "binomial") 
summary(reg)
#Coefficients:
#              Estimate Std. Error z value Pr(>|z|)    
#(Intercept)   -10.9813     2.8919  -3.797 0.000146 ***
#  Experience    1.1269     0.2909   3.874 0.000107 ***
#  Training      0.1805     0.3386   0.533 0.593970    

library(caret)
confusionMatrix(factor(ifelse(reg$fitted.values > 0.5, "Yes", "No")), 
                admin.df$Completed.task)
#Confusion Matrix and Statistics
#
#            Reference
#Prediction     No Yes
#       No      58   5
#      Yes       2  10
#
#Accuracy : 0.9067

#Among those who completed the task (15), 5 are misclassified as failing to complete
#the tast. So the percentage of programmers incorrectly classified as failing to
#complete task is 5/15 = 33.33%.

##10.2.c To decrease the percentage in part (b), should the cutoff probability 
##be increased or decreased?

#lowering the cutoff will lead to a reduced (or equal) classification error 
#rate for truly completed records.

##10.2.d How much experience must be accumulated by a programmer with 4 years of
##training before his or her estimated probability of completing the task 
##exceeds 0.5?

#The cutoff of 0.5 on the probability of task completion is equivalent to a 
#threshold of 0 on the logit. We therefore write the estimated logit equation, 
#equate it to 0 and set Training=4.
#let's say p = 0.6
#Logit = ln [(p) / (1-p)] = 0.4055 = -10.9794 + 1.1267*Experience + 0.1805*Training.
#We plug Training = 4 and solve for Experience.
#9.464 months experience must be accumulated by a programmer with 4 years of 
#education before his/her estimated probability of completing the task exceeds 50%.

#############################

## Problem 10.3 Sales of Riding Mowers. 
##A company that manufactures riding mowers wants to identify the best sales 
##prospects for an intensive sales campaign. In particular, the manufacturer
##is interested in classifying households as prospective owners or nonowners 
##on the basis of Income (in $1000s) and Lot Size (in 1000 ft2). The marketing
##expert looked at a random sample of 24 households, given in the file 
##RidingMowers.csv. Use all the data to fit a logistic regression of ownership
##on the two predictors.

#load the data
mowers.df <-read.csv("RidingMowers.csv")

##10.3.a What percentage of households in the study were owners of a riding 
##mower?

table(mowers.df$Ownership)
#Nonowner    Owner 
#12          12 

#There are 12 out 24 records with ownership=owner.
#Therefore 50% of households were owners of riding mowers.

##10.3.b Create a scatter plot of Income vs. Lot Size using color or symbol to 
##distinguish owners from nonowners. From the scatter plot, which class seems 
##to have a higher average income, owners or nonowners?

#scatter plot of Income Vs. Lot Size

plot(Income ~ Lot_Size, data = mowers.df, col = (mowers.df$Ownership == "Owner")+1)

#From the scatterplot it appears that "owners" tend to have a higher average 
#income.

##10.3.c Among nonowners, what is the percentage of households classified 
##correctly?

#fit the logistic regression model and obtain the summary
reg<-glm(Ownership ~ ., data = mowers.df, family = "binomial") 
summary(reg)
#Coefficients:
#              Estimate Std. Error z value Pr(>|z|)  
#(Intercept)   -25.9382    11.4871  -2.258   0.0239 *
#  Income        0.1109     0.0543   2.042   0.0412 *
#  Lot_Size      0.9638     0.4628   2.083   0.0373 *

library(caret)
confusionMatrix(factor(ifelse(reg$fitted.values > 0.5, "Owner", "Nonowner")), 
                mowers.df$Ownership, positive = "Owner")
#> confusionMatrix(factor(ifelse(reg$fitted.values > 0.5, "Owner", "Nonowner")), 
#+                 mowers.df$Ownership, positive = "Owner")
#Confusion Matrix and Statistics
#
#          Reference
#Prediction Nonowner Owner
#  Nonowner       10     2
#  Owner           2    10
#
#                   Accuracy : 0.833         
#                     95% CI : (0.626, 0.953)
#       No Information Rate : 0.5           
#       P-Value [Acc > NIR] : 0.000772      
#
#                     Kappa : 0.667         
#
#    Mcnemar's Test P-Value : 1.000000      
#
#               Sensitivity : 0.833         
#               Specificity : 0.833         
#            Pos Pred Value : 0.833         
#            Neg Pred Value : 0.833         
#                Prevalence : 0.500         
#            Detection Rate : 0.417         
#      Detection Prevalence : 0.500         
#         Balanced Accuracy : 0.833         
#
#          'Positive' Class : Owner
#

#Out of 12 actual nononwers 10 are classified correctly so 10/12 = 83.33%.

##10.3.d To increase the percentage of correctly classified nonowners, should 
##the cutoff probability be increased or decreased?

#From the classification confusion matrix shown in (c) we can see that 10 of 
#the 12 non-owners are correctly classified. If we increase the cutoff 
#(i.e. make it harder to be classified as an owner), we can reduce the number 
#of non-owners misclassified as owners, and improve the classification 
#performance with non-owners. (Of course, this will be at the cost of 
#misclassifying more of the owners as non-owners.)

##10.3.e What are the odds that a household with a $60K income and a lot size 
##of 20,000 ft2 is an owner?

names(mowers.df)
Income <- 60; 
Lot_Size <- 20
odds <- exp(-25.9382 + 0.1109 * Income + 0.9638 * Lot_Size)
odds
#[1] 0.9918335

##10.3.f What is the classification of a household with a $60K income and a lot
##size of 20,000 ft2? Use cutoff = 0.5.

# new record
logit <- c(1, 60, 20) %*% reg$coefficients
odds <- exp(-logit)
prob <- 1/(1+odds)
prob
logit

#probability that the new household is 0.4972 and thus the predicted class 
#for this new household is 0, or "non-owner".

##10.3.g What is the minimum income that a household with 16,000 ft2 lot size 
##should have before it is classified as an owner?

#The cutoff of 0.5 on the probability of owner is equivalent to a 
#threshold of 0 on the logit. We therefore write the estimated logit equation, 
#equate it to 0 and set Lot_Size=16.

#0 = -25.9382 + 0.1109*Income + 0.9638*Lot_Size.
#We plug Lot_Size = 16 and solve for Income.
Income <- (25.9382 - (0.9638*16)) / 0.1109
Income

#The minimum income needed for this household to be classified as "owner" is 
#$94.8368K

#############################

##Problem 10.4 Competitive Auctions on eBay.com. 
##The file eBayAuctions.csv contains information on 1972 auctions transacted 
##on eBay.com during May-June 2004. The goal is to use these data to build a 
##model that will distinguish competitive auctions from noncompetitive ones. 
##A competitive auction is defined as an auction with at least two bids placed 
##on the item being auctioned. The data include variables that describe the
##item (auction category), the seller (his or her eBay rating), and the auction
##terms that the seller selected (auction duration, opening price, currency, 
##day of week of auction close). In addition, we have the price at which the 
##auction closed. The goal is to predict whether or not an auction of interest
##will be competitive.
##Data preprocessing. Create dummy variables for the categorical predictors.
##These include Category (18 categories), Currency (USD, GBP, Euro), EndDay
##(Monday-Sunday), and Duration (1, 3, 5, 7, or 10 days).

#load the data
ebay.df <- read.csv("ebayAuctions.csv", stringsAsFactors = FALSE)

##10.4.a Create pivot tables for the mean of the binary outcome (Competitive?) 
##as a function of the various categorical variables (use the original variables,
##not the dummies). Use the information in the tables to reduce the number of 
##dummies that will be used in the model. For example, categories that appear 
##most similar with respect to the distribution of competitive auctions could
##be combined.

data.frame(tapply(ebay.df$Competitive., ebay.df$Category, mean))
data.frame(tapply(ebay.df$Competitive., ebay.df$currency, mean))
data.frame(tapply(ebay.df$Competitive., ebay.df$endDay, mean))
data.frame(tapply(ebay.df$Competitive., ebay.df$Duration, mean))

#The categories "Business/Industrials" and "Computers" have same average of 
#the binary variable "Competitive." This means that the percentage of 
#competitive auctions in each of these two categories is equal. Hence we can 
#combine the two categories into a single category called "Computers."
#Similarly, the average of "competitive" for the categories "Antique/Art/Craft"
#and "Collectibles" are almost same. Therefore, we can combine them into a 
#single category called "collectibles".
#The auction ending days "Sunday" and "Friday" have approximately equal 
#averages for "competitive". So we can combine them into a single category 
#called "Sun_Fri".

names(ebay.df)
ebay.df$endDay[ebay.df$endDay == "Sun"] <- "Sun_Fri"
ebay.df$endDay[ebay.df$endDay == "Fri"] <- "Sun_Fri"
ebay.df$Category[ebay.df$Category == "Business/Industrial"] <- "Computer"
ebay.df$Category[ebay.df$Category == "Antique/Art/Craft"] <- "Collectibles"

##10.4.b Split the data into training (60%) and validation (40%) datasets. Run 
##a logistic model with all predictors with a cutoff of 0.5.

#data partition
ntotal <- length(ebay.df$Competitive.)
ntrain <- round(ntotal * 0.6)
nvalid <- ntotal - ntrain
set.seed(202)  # Seed of random number generator for reproducibility.
ntrain.index <- sort(sample(ntotal, ntrain))  # Sample rows randomly.
train.df <- ebay.df[ntrain.index, ]
valid.df <- ebay.df[-ntrain.index, ]
options(scipen = 999, digits = 4)

#logistic regression using all the variables
reg <- glm(Competitive. ~ ., data = train.df, family = "binomial")
summary(reg)
#> summary(reg)
#
#Call:
#  glm(formula = Competitive. ~ ., family = "binomial", data = train.df)
#
#Deviance Residuals: 
#   Min      1Q  Median      3Q     Max  
#-6.813  -0.919   0.003   0.882   2.380  
#
#Coefficients:
#                               Estimate Std. Error z value             Pr(>|z|)    
#(Intercept)                  -0.0684576  0.5010851   -0.14               0.8913    
#CategoryBooks                -0.1875809  0.5045616   -0.37               0.7101    
#CategoryClothing/Accessories -0.7640455  0.4900804   -1.56               0.1190    
#CategoryCoins/Stamps         -0.6620383  0.6405184   -1.03               0.3013    
#CategoryCollectibles          0.6128959  0.3487541    1.76               0.0789 .  
#CategoryComputer              0.2877405  0.5093094    0.56               0.5721    
#CategoryElectronics           0.6004863  0.5599910    1.07               0.2836    
#CategoryEverythingElse       -1.4848764  1.1249556   -1.32               0.1869    
#CategoryHealth/Beauty        -1.5777915  0.6095667   -2.59               0.0096 ** 
#CategoryHome/Garden           0.2221810  0.4450222    0.50               0.6176    
#CategoryJewelry              -0.0178390  0.4521957   -0.04               0.9685    
#CategoryMusic/Movie/Game      0.4764288  0.3509678    1.36               0.1746    
#CategoryPhotography           0.3055007  1.1127369    0.27               0.7837    
#CategoryPottery/Glass        -0.1721011  0.8091444   -0.21               0.8316    
#CategorySportingGoods         0.2919242  0.4653412    0.63               0.5304    
#CategoryToys/Hobbies          0.7684393  0.3573958    2.15               0.0315 *  
#currencyGBP                   1.6994722  0.5350996    3.18               0.0015 ** 
#currencyUS                    0.1847873  0.2183158    0.85               0.3973    
#sellerRating                 -0.0000392  0.0000164   -2.39               0.0170 *  
#Duration                     -0.0032030  0.0436085   -0.07               0.9414    
#endDaySat                    -1.1856262  0.2309848   -5.13           0.00000029 ***
#endDaySun_Fri                -0.5651575  0.1960152   -2.88               0.0039 ** 
#endDayThu                    -1.3680613  0.4951106   -2.76               0.0057 ** 
#endDayTue                    -0.6157027  0.2882909   -2.14               0.0327 *  
#endDayWed                    -0.9015452  0.4394919   -2.05               0.0402 *  
#ClosePrice                    0.0956000  0.0105914    9.03 < 0.0000000000000002 ***
#OpenPrice                    -0.1119346  0.0122464   -9.14 < 0.0000000000000002 ***
#  ---
#  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#
#(Dispersion parameter for binomial family taken to be 1)
#
#Null deviance: 1632.7  on 1182  degrees of freedom
#Residual deviance: 1217.0  on 1156  degrees of freedom
#AIC: 1271
#
#Number of Fisher Scoring iterations: 8

#predictions on validation data
pred <- predict(reg, newdata = valid.df, type = "response")
head(pred)

#confusion matrix
library(caret)
confusionMatrix(factor(ifelse(pred > 0.5, 1, 0)), 
                factor(valid.df$Competitive.), positive = "1")
#> confusionMatrix(factor(ifelse(pred > 0.5, 1, 0)), 
#+                 factor(valid.df$Competitive.), positive = "1")
#Confusion Matrix and Statistics
#
#          Reference
#Prediction   0   1
#         0 281  85
#         1  80 343
#
#               Accuracy : 0.791              
#                 95% CI : (0.761, 0.819)     
#    No Information Rate : 0.542              
#    P-Value [Acc > NIR] : <0.0000000000000002
#
#                  Kappa : 0.579              
#
# Mcnemar's Test P-Value : 0.755              
#
#            Sensitivity : 0.801              
#            Specificity : 0.778              
#         Pos Pred Value : 0.811              
#         Neg Pred Value : 0.768              
#             Prevalence : 0.542              
#         Detection Rate : 0.435              
#   Detection Prevalence : 0.536              
#      Balanced Accuracy : 0.790              
#
#       'Positive' Class : 1

##10.4.c If we want to predict at the start of an auction whether it will be
##competitive, we cannot use the information on the closing price. Run a 
##logistic model with all predictors as above, excluding price. How does this 
##model compare to the full model with respect to predictive accuracy?

#logistic regresssion excluding closing price variable
reg <- glm(Competitive. ~ ., data = train.df[-6], family = "binomial")
#predictions on validation data
pred <- predict(reg, newdata = valid.df, type = "response")
head(pred)
#confusion matrix
confusionMatrix(factor(ifelse(pred > 0.5, 1, 0)), 
                factor(valid.df$Competitive.), positive = "1")
#> confusionMatrix(factor(ifelse(pred > 0.5, 1, 0)), 
#+                 factor(valid.df$Competitive.), positive = "1")
#Confusion Matrix and Statistics
#
#          Reference
#Prediction   0   1
#         0 201 116
#         1 160 312
#
#                Accuracy : 0.65          
#                  95% CI : (0.616, 0.683)
#     No Information Rate : 0.542         
#     P-Value [Acc > NIR] : 0.000000000535
#
#                   Kappa : 0.289         
#
#  Mcnemar's Test P-Value : 0.00965       
#
#             Sensitivity : 0.729         
#             Specificity : 0.557         
#          Pos Pred Value : 0.661         
#          Neg Pred Value : 0.634         
#              Prevalence : 0.542         
#          Detection Rate : 0.395         
#    Detection Prevalence : 0.598         
#       Balanced Accuracy : 0.643         
#
#'Positive' Class : 1
#

#The overall error rate for the full model (20.9%) is much lower than that for 
#the model excluding "close price" (35%). Hence the model excluding "close price"
#has lower predictive accuracy compared to the full model.

##10.4.d Interpret the meaning of the coefficient for closing price. Does 
##closing price have a practical significance? Is it statistically significant
##for predicting competitiveness of auctions? (Use a 10% significance level.)

#The coefficient for "close price" is 0.0956. This positive coefficient means 
#that higher closing prices are associated with a higher probability of the 
#auction being competitive. Looking at the odds coefficient (1.1), we see 
#that every $1 increase in the closing price increases the odds of the auction
#being competitive by a factor of 1.1.

#Testing of Hypothesis:
#  Null hypothesis: Coefficient of closing price is zero in the regression 
#  model. (Closing price does not contribute to the model)
#  Alternate hypothesis: Coefficient of closing price is non-zero in the 
#  regression model. (Closing price contributes to the model)
#  The p-value for coefficient of "close price" is 0.
#  We reject the above null hypothesis if significance level  p-value.
#  In our case the significance level = 0.1 > p-value = 0. Therefore we reject 
#  the above null hypothesis.

#  Closing price is statistically significant (at 0.10 significance level) in 
#  the regression model for predicting competitiveness of auctions.

#We will not use ClosePrice in the remaining questions since closing price won't
#be available at the time making predictions.

##10.4.e Use stepwise selection (use function step() in the stats package or 
##function stepAIC() in the MASS package) and an exhaustive search (use 
##function glmulti() in package glmulti) to find the model with the best fit
##to the training data. Which predictors are used?

#stepwise logistic regression
#we use the function stepAIC from the package MASS 
library(MASS)
stepwise <- stepAIC(reg, direction = "both")
summary(stepwise)
#> summary(stepwise)
#
#Call:
#  glm(formula = Competitive. ~ Category + currency + sellerRating + 
#        Duration + endDay, family = "binomial", data = train.df[-6])
#
#Deviance Residuals: 
#   Min      1Q  Median      3Q     Max  
#-1.979  -1.080   0.699   1.018   2.326  
#
#Coefficients:
#                               Estimate Std. Error z value       Pr(>|z|)    
#(Intercept)                   1.0435392  0.4064598    2.57        0.01025 *  
#CategoryBooks                -0.0001252  0.4235101    0.00        0.99976    
#CategoryClothing/Accessories  0.5576782  0.3667870    1.52        0.12840    
#CategoryCoins/Stamps         -0.8013464  0.5520407   -1.45        0.14661    
#CategoryCollectibles          1.0807095  0.2597445    4.16 0.000031732454 ***
#CategoryComputer              1.0342263  0.4125733    2.51        0.01218 *  
#CategoryElectronics           1.3066418  0.4420391    2.96        0.00312 ** 
#CategoryEverythingElse       -1.5803968  1.1050591   -1.43        0.15267    
#CategoryHealth/Beauty        -1.5345874  0.5375881   -2.85        0.00431 ** 
#CategoryHome/Garden           0.8144780  0.3604949    2.26        0.02386 *  
#CategoryJewelry               0.1580718  0.3889220    0.41        0.68442    
#CategoryMusic/Movie/Game      0.5104741  0.2691387    1.90        0.05787 .  
#CategoryPhotography           1.3421670  0.8851661    1.52        0.12945    
#CategoryPottery/Glass        -0.3151138  0.6618639   -0.48        0.63400    
#CategorySportingGoods         1.6810970  0.3666760    4.58 0.000004546541 ***
#CategoryToys/Hobbies          0.9674169  0.2812344    3.44        0.00058 ***
#currencyGBP                   1.6007954  0.4643719    3.45        0.00057 ***
#currencyUS                   -0.1290081  0.1927364   -0.67        0.50327    
#sellerRating                 -0.0000519  0.0000140   -3.72        0.00020 ***
#Duration                     -0.0841031  0.0371896   -2.26        0.02373 *  
#endDaySat                    -1.3681042  0.2077648   -6.58 0.000000000046 ***
#endDaySun_Fri                -0.9782467  0.1809211   -5.41 0.000000064077 ***
#endDayThu                    -1.6965571  0.4154427   -4.08 0.000044317969 ***
#endDayTue                    -0.8145414  0.2582039   -3.15        0.00161 ** 
#endDayWed                    -0.8220766  0.3795056   -2.17        0.03030 *  
#  ---
#  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#
#(Dispersion parameter for binomial family taken to be 1)
#
#Null deviance: 1632.7  on 1182  degrees of freedom
#Residual deviance: 1469.3  on 1158  degrees of freedom
#AIC: 1519
#
#Number of Fisher Scoring iterations: 4

#Using the stepwise method, the "best model" contains 24 predictors (as shown in 
#the table above). For this model AIC=1519. 

#NOTE for INSTRUCTOR
#exhaustive search (or best subset)
#here glmulti package is not workin without rJava. 
#We try bestglm package instead (below) but that also limits the number of 
#predictors to max 15. Threfore, simply stick to the stepwise method, and/or
#use this as an illustration of the computational limitations of exhaustive 
#search.

#ATEMPT USING PACKAGE "glmulti"
#install.packages("glmulti")
#install.packages("rJava")
#library(rJava)
#install.packages('rJava','http://www.rforge.net/')
#library(glmulti)
#need to be redone after successfully installing glmulti package
#exhaust <- glmulti(Competitive., xr = c("Category", "currency", "sellerRating",
#                                        "Duration", "endDay", "OpenPrice"), 
#                   data = train.df)

#ATEMPT USING PACKAGE "bestglm"
#install.packages("bestglm")
#library(bestglm)
#bestglm input needs converting categorical predictors to dummies first
#library(dummies)
#ctgr <- as.data.frame(dummy(factor(train.df$Category)))
#crnc <- as.data.frame(dummy(factor(train.df$currency)))
#endd <- as.data.frame(dummy(factor(train.df$endDay)))
#trainset <- train.df[,-c(1,2,5)]
#train.dummy <- cbind(ctgr,crnc,endd,trainset)
#best.model <- bestglm(train.dummy, IC="AIC", family = binomial)

##10.4.f. Use stepwise selection and an exhaustive search to find the model with
##the lowest predictive error rate (use the validation data). Which predictors 
##are used?

#predictive error rate using stepwise selection (training set)
pred <- predict(reg, newdata = train.df, type = "response")
#confusion matrix
confusionMatrix(factor(ifelse(pred > 0.5, 1, 0)), 
                factor(train.df$Competitive.), positive = "1")

#predictive error rate using stepwise selection (Validation set)
pred <- predict(reg, newdata = valid.df, type = "response")
#confusion matrix
confusionMatrix(factor(ifelse(pred > 0.5, 1, 0)), 
                factor(valid.df$Competitive.), positive = "1")


##10.4.g What is the danger of using the best predictive model that you found?

#we stick to stepwise selection search
#The best predictive model (using stepwise selection) contains 24 predictors, 
#which might be overfitting the training data. One way to evaluate the degree 
#of overfitting is to compare the error rates of the training and validation 
#sets. The large difference in training set error and validation error (where 
#training set error is smaller than validation set) indicates that the model 
#may be overfit to the training data.
#In addition, the best model contains coefficients, which are not statistically
#significant. These are further indications that we should reduce the
#number of predictors further to avoid overfitting.

##10.4.h Explain why the best-fitting model and the best predictive models are 
##same or different.

#While finding the best-fitted model means fitting the training data set (using
#measures like Rsquared), the best predictive model is one that has highest 
#prediction accuracy with the validation data (using measures like error rates).

##10.4.i If the major objective is accurate classification, what cutoff value 
##should be used?

##10.4.j Based on these data, what auction settings set by the seller (duration,
##opening price, ending day, currency) would you recommend as being most likely
##to lead to a competitive auction?
