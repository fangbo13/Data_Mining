df <- read.csv("liftExample.csv")
# create empty accuracy table
accT = c()
# compute accuracy per cutoff
for (cut in seq(0,1,0.1)){
cm <- confusionMatrix(as.factor(1 * (df$prob > cut)), as.factor(df$actual))
accT = c(accT, cm$overall[1])
}
df
df$prob > cut
cut <- 0.1
cm <- confusionMatrix(as.factor(1 * (df$prob > cut)), as.factor(df$actual))
cm
c(accT, cm$overall[1])
# create empty accuracy table
accT = c()
# compute accuracy per cutoff
for (cut in seq(0,1,0.1)){
cm <- confusionMatrix(as.factor(1 * (df$prob > cut)), as.factor(df$actual))
accT = c(accT, cm$overall[1])
}
# plot accuracy
plot(accT ~ seq(0,1,0.1), xlab = "Cutoff Value", ylab = "", type = "l", ylim = c(0, 1))
lines(1-accT ~ seq(0,1,0.1), type = "l", lty = 2)
legend("topright",  c("accuracy", "overall error"), lty = c(1, 2), merge = TRUE)
cm$overall
library(pROC)
r <- roc(df$actual, df$prob)
plot.roc(r)
# compute auc
auc(r)
r$thresholds[c(1,25)] <- c(0,1)
plot(r$sensitivities, r$specificities)
points(seq(0,1,length.out = 25),r$thresholds, col = "green", pch = 2)
#### Table 2.6
# Option 1: use dummies package
# install.packages(dummies)
library(dummies)
housing.df <- dummy.data.frame(housing.df, sep = ".")
install.packages("dummies")
#### Table 2.6
# Option 1: use dummies package
# install.packages(dummies)
library(dummies)
install.packages("dummies")
remotes::install_github("https://github.com/cran/dummies")
#### Table 2.6
# Option 1: use dummies package
# install.packages(dummies)
library(dummies)
housing.df
# Option 2: use model.matrix() to convert all categorical variables in the data frame into a set of dummy variables. We must then turn the resulting data matrix back into
# a data frame for further work.
housing.df <- read.csv("WestRoxbury.csv", header = TRUE)  # load data
housing.df
head(housing.df)
unique(housing.df$REMODEL)
?dummy.data.frame
housing.df <- dummy.data.frame(housing.df, sep = ".")
warnings()
names(housing.df)
housing.df <- dummy.data.frame(housing.df, sep = ".", drop = T)
boxplot(housing.df$TOTAL.VALUE)
housing.df$TOTAL.VALUE > 1200
names(housing.df$TOTAL.VALUE[housing.df$TOTAL.VALUE > 1200])
rownames(housing.df[housing.df$TOTAL.VALUE > 1200, "TOTAL.VALUE"])
names(housing.df[housing.df$TOTAL.VALUE > 1200, "TOTAL.VALUE"])
# load file
toyota.corolla.df <- read.csv("ToyotaCorolla.csv")
# run linear regression model
reg <- lm(Price~., data=toyota.corolla.df[,-c(1,2,6,8,11,15,37,38)], subset=training,
na.action=na.exclude)
# randomly generate training and validation sets
training <- sample(toyota.corolla.df$Id, 600)
validation <- sample(setdiff(toyota.corolla.df$Id, training), 400)
# run linear regression model
reg <- lm(Price~., data=toyota.corolla.df[,-c(1,2,6,8,11,15,37,38)], subset=training,
na.action=na.exclude)
cooks.distance(reg)
round(cooks.distance(reg),2)
plot(reg)
summary(regr)
summary(reg)
round(summary(reg),2)
round(reg$effects,2)
summary(reg)
# run linear regression model
reg <- lm(Price~., scale(data=toyota.corolla.df[,-c(1,2,6,8,11,15,37,38)]), subset=training,
na.action=na.exclude)
# run linear regression model
reg <- lm(Price~., data=scale(toyota.corolla.df[,-c(1,2,6,8,11,15,37,38)]), subset=training,
na.action=na.exclude)
data <- scale(toyota.corolla.df[,-c(1,2,6,8,11,15,37,38)])
# run linear regression model
reg <- lm(Price~., data=data, subset=training,
na.action=na.exclude)
data <- as.matrix(scale(toyota.corolla.df[,-c(1,2,6,8,11,15,37,38)]))
# run linear regression model
reg <- lm(Price~., data=data, subset=training,
na.action=na.exclude)
data <- as.data.frame(scale(toyota.corolla.df[,-c(1,2,6,8,11,15,37,38)]))
# run linear regression model
reg <- lm(Price~., data=data, subset=training,
na.action=na.exclude)
summary(reg)
(toyota.corolla.df$Price - mean(toyota.corolla.df$Price))/sd(toyota.corolla.df$Price)
scale(toyota.corolla.df)
scale(toyota.corolla.df$Price)
# Normalize / Standardize
plot(density(housing.df[,1]))
scale(housing.df[,1])
plot(scale(housing.df$TOTAL.VALUE))
# Normalize / Standardize
plot(density(housing.df[,1]))
plot(density(scale(housing.df[,1])))
?cor
# Principle Components Analysis ----
decathlon <- read.csv(file = "decathlon_data.txt", sep="\t", header = TRUE)
View(decathlon)
head(housing.df)  # show the first six rows
# load file
toyota.corolla.df <- read.csv("ToyotaCorolla.csv")
View(toyota.corolla.df)
# run linear regression model
reg <- lm(Price ~ Fuel_Type _ Color - 1, data=data, subset=training,
# run linear regression model
reg <- lm(Price ~ Fuel_Type + Color - 1, data=data, subset=training,
na.action=na.exclude)
colnames(data)
# run linear regression model
reg <- lm(Price ~ Fuel_Type + Color - 1, data=toyota.corolla.df,
na.action=na.exclude)
summary(reg)
table(toyota.corolla.df$Fuel_Type)
table(toyota.corolla.df$Fuel_Type, toyota.corolla.df$Color)
toyota.corolla.df$Fuel_Type == "Petrol"
sort_vec <- toyota.corolla.df$Color == "Grey" & toyota.corolla.df$Fuel_Type == "Petrol"
toyota.corolla.df[sort_vec, ]
toyota.corolla.df[sort_vec, "Price"]
mean(toyota.corolla.df[sort_vec, "Price"])
summary(reg)
toyota.corolla.df[sort_vec, "Price"]
plot(density(toyota.corolla.df[sort_vec, "Price"]))
reg <- lm(Price ~ Fuel_Type + Color + Mfg_Year - 1, data=toyota.corolla.df,na.action=na.exclude)
summary(regr)
summary(reg)
round(2reg$coefficients
round(reg$coefficients,2)
year_made <-
as.factor(toyota.corolla.df$Mfg_Year)
data <- cbind(toyota.corolla.df, year_made)
reg <- lm(Price ~ Fuel_Type + Color + year_made - 1, data=toyota.corolla.df,na.action=na.exclude)
summary(reg)
library(skimr)
# install.packages("skimr")
library(skimr)
housing.df <- read.csv("WestRoxbury.csv", header = TRUE)  # load data
dim(housing.df)  # find the dimension of data frame
head(housing.df)  # show the first six rows
View(housing.df)  # show all the data in a new tab
skim(housing.df)
summary(housing.df)  # find summary statistics for each column
# Normalize / Standardize
scale(housing.df[,1])
plot(density(scale(housing.df[,1])))
skim(housing.df)
boxplot(housing.df[,1])
apply(housing.df[,-14],2, sd)
plot(density(housing.df[,2]))
round(cor(housing.df[,-14]), 2)
round(colMeans(housing.df[,-14]),2)
abline(v = mean(housing.df[,2]), col = "green")
abline(v = mean(housing.df[,2])+(c(-1,1)*sd(housing.df[,2])), lty = 2, col = "red")
plot(housing.df[,"LOT.SQFT"], housing.df[,"TOTAL.VALUE"])
# random sample of 500 observations
s <- sample(row.names(housing.df), 50)
round(cor(housing.df[,-14]), 2)
s
# Some descriptive stats
boxplot(housing.df[,1])
apply(housing.df[,-14],2, sd)
plot(density(housing.df[,2]))
round(cor(housing.df[,-14]), 2)
round(colMeans(housing.df[,-14]),2)
abline(v = mean(housing.df[,2]), col = "green")
abline(v = mean(housing.df[,2])+(c(-1,1)*sd(housing.df[,2])), lty = 2, col = "red")
plot(housing.df[,"LOT.SQFT"], housing.df[,"TOTAL.VALUE"])
# Now we look at some resampling: Lets take a random subset of 500 observations.
s <- sample(row.names(housing.df), 50)
round(cor(housing.df[,-14]), 2)
round(cor(housing.df[s,-14]),2)
round(cor(housing.df[1:500,-14]),2)
round(colMeans(housing.df[,-14]),2)
round(colMeans(housing.df[s,-14]),2)
round(colMeans(housing.df[1:500,-14]),2)
# oversample houses with over 10 rooms
s1 <- sample(row.names(housing.df), 10, prob = ifelse(housing.df$ROOMS>10, 0.9, 0.01))
s2 <- sample(row.names(housing.df), 10)
s1
s2
ifelse(housing.df$ROOMS>10, 0.9, 0.01)
round(cor(housing.df[s2,-14]),2)
# How do subsets affect our metrics? Lets do probability sampling.
s1 <- sample(row.names(housing.df), 10, prob = ifelse(housing.df$ROOMS>10, 0.9, 0.01))
s2 <- sample(row.names(housing.df), 10)
round(cor(housing.df[s2,-14]),2)
# How do subsets affect our metrics? Lets do probability sampling.
s1 <- sample(row.names(housing.df), 10, prob = ifelse(housing.df$ROOMS>10, 0.9, 0.01))
s2 <- sample(row.names(housing.df), 10)
round(cor(housing.df[s2,-14]),2)
round(cor(housing.df[s1,-14]),2)
names(housing.df)  # print a list of variables to the screen.
library(dummies)
skim(housing.df)
# Types of variables ----
housing.df$BEDROOMS
unique(housing.df$BEDROOMS)
# Types of variables ----
skim(housing.df$BEDROOMS)
factor(housing.df$BEDROOMS)
table(housing.df$BEDROOMS)
boxplot(housing.df)
boxplot(housing.df[,1:13])
boxplot(scale(housing.df[,1:13]))
# Remodel: categorical?
skim(housing.df$REMODEL)
# Remodel: categorical?
table(housing.df$REMODEL)
# Types of variables ----
# Bedrooms: ordinal??
skim(housing.df$BEDROOMS)
table(housing.df$BEDROOMS)
#
table(housing.df$TOTAL.VALUE)
# Types of variables ----
# Bedrooms: ordinal??
boxplot(housing.df$BEDROOMS)
table(housing.df$BEDROOMS)
# Remodel: categorical??
boxplot(housing.df$REMODEL)
# Total Value: ratio??
boxplot(housing.df$TOTAL.VALUE)
table(housing.df$TOTAL.VALUE)
# Total Value: ratio??
barplot(housing.df$TOTAL.VALUE)
# Remodel: categorical??
barplot(housing.df$REMODEL)
# Remodel: categorical??
barplot(housing.df$REMODEL)
# Types of variables ----
# Bedrooms: ordinal??
barplot(housing.df$BEDROOMS)
# Types of variables ----
# Bedrooms: ordinal??
boxplot(housing.df$BEDROOMS)
table(housing.df$BEDROOMS)
# Option 1: use dummies package
housing.df <- dummy.data.frame(housing.df, sep = ".")
library(dummies)
# Option 1: use dummies package
housing.df <- dummy.data.frame(housing.df, sep = ".")
install.packages("dummies")
# Option 1: use dummies package
housing.df <- dummy.data.frame(housing.df, sep = ".")
library(dummies)
# Creating Dummies ----
# Use model.matrix() to convert all categorical variables in the data
# frame into a set of dummy variables. We must then turn the resulting data
# matrix back into a data frame for further work.
housing.df <- read.csv("WestRoxbury.csv", header = TRUE)  # load data
# Creating Dummies ----
# Use model.matrix() to convert all categorical variables in the data
# frame into a set of dummy variables. We must then turn the resulting data
# matrix back into a data frame for further work.
xtotal <- model.matrix(~ 0 + REMODEL, data = housing.df)
xtotal
t(t(names(xtotal)))  # check the names of the dummy variables
names(xtotal) # check the names of the dummy variables
xtotal <- as.data.frame(xtotal)
names(xtotal)
head(xtotal)
cbind(housing.df$REMODEL, xtotal)
head(cbind(housing.df$REMODEL, xtotal))
head(cbind(housing.df$REMODEL, xtotal))
# Outliers ----
summary(housing.df)
# Outliers ----
skim(housing.df)
boxplot(housing.df$TOTAL.VALUE)
plot(density(housing.df$TOTAL.VALUE))
abline(v = quantile(housing.df$TOTAL.VALUE, probs = c(0.001, 0.999)))
plot(scale(housing.df$TOTAL.VALUE))
boxplot(housing.df$YR.BUILT)
# install.packages("skimr")
# install.packages(dummies)
# install.packages("seminr")
remotes::install_github("https://github.com/soumyaray/compstatslib.git")
# install.packages("skimr")
# install.packages(dummies)
# install.packages("seminr")
# remotes::install_github("https://github.com/soumyaray/compstatslib.git")
library(compstatslib)
compstatslib::interactive_regression()
# Outliers ----
# What do they do?
compstatslib::interactive_regression()
# Outliers ----
# What do they do?
compstatslib::interactive_regression()
# Standardize data ----
# Does it affect the shape?
scale(housing.df[,1])
plot(density(scale(housing.df[,1])))
# Standardize data ----
# Does it affect the shape?
plot(density(housing.df[,1]))
plot(density(scale(housing.df[,1])))
install.packages("naniar")
library(naniar)
naniar::mcar_test(housing.df)
# Missing Values ----
# To illustrate missing data procedures, we first convert a few entries for
# bedrooms to NA's. Then we impute these missing values using the median of the
# remaining values.
rows.to.missing <- sample(row.names(housing.df), 10)
housing.df[rows.to.missing,]$BEDROOMS <- NA
summary(housing.df$BEDROOMS)  # Now we have 10 NA's and the median of the
# remaining values is 3.
naniar::mcar_test(housing.df$BEDROOMS)
# remaining values is 3.
naniar::mcar_test(housing.df)
# remaining values is 3.
summary(naniar::mcar_test(housing.df))
# remaining values is 3.
nick <- naniar::mcar_test(housing.df)
# Now lets use Little's test fopr MCAR:
naniar::mcar_test(housing.df)
# Now lets use Little's test fopr MCAR:
naniar::mcar_test(housing.df[,"BEDROOMS"])
# Now lets use Little's test fopr MCAR:
naniar::mcar_test(as.data.frame(housing.df[,"BEDROOMS"]))
rows.to.missing
# Load the data:
housing.df <- read.csv("WestRoxbury.csv", header = TRUE)  # load data
# Now lets use Little's test fopr MCAR:
naniar::mcar_test(as.data.frame(housing.df[,"BEDROOMS"]))
# Now lets use Little's test fopr MCAR:
naniar::mcar_test(housing.df)
# Missing Values ----
# To illustrate missing data procedures, we first convert a few entries for
# bedrooms to NA's. Then we impute these missing values using the median of the
# remaining values.
rows.to.missing <- sample(row.names(housing.df), 10)
housing.df[rows.to.missing,]$BEDROOMS <- NA
summary(housing.df$BEDROOMS)  # Now we have 10 NA's and the median of the
# Now lets use Little's test fopr MCAR:
naniar::mcar_test(housing.df)
mcar_test(airquality)
# Now lets use Little's test fopr MCAR:
naniar::mcar_test(housing.df)
# Load the data:
housing.df <- read.csv("WestRoxbury.csv", header = TRUE)  # load data
# Missing Values ----
# Now lets use Little's test fopr MCAR:
naniar::mcar_test(housing.df)
# Missing Values ----
# Now lets use Little's test fopr MCAR:
# H0: MCAR
# H1: Not MCAR
naniar::mcar_test(housing.df)
# To illustrate missing data procedures, we first convert a few entries for
# bedrooms to NA's. Then we impute these missing values using the median of the
# remaining values.
rows.to.missing <- sample(row.names(housing.df), 10)
housing.df[rows.to.missing,]$BEDROOMS <- NA
summary(housing.df$BEDROOMS)  # Now we have 10 NA's and the median of the
# Now lets use Little's test fopr MCAR:
naniar::mcar_test(housing.df)
# Missing Values ----
# Load the data:
housing.df <- read.csv("WestRoxbury.csv", header = TRUE)  # load data
# Now lets use Little's test fopr MCAR:
# H0: MCAR
# H1: Not MCAR
naniar::mcar_test(housing.df)
# To illustrate missing data procedures, we first convert a few entries for
# bedrooms to NA's. Then we impute these missing values using the median of the
# remaining values.
rows.to.missing <- sample(row.names(housing.df), 10)
housing.df[rows.to.missing,]$BEDROOMS <- NA
summary(housing.df$BEDROOMS)  # Now we have 10 NA's and the median of the
# Now lets use Little's test fopr MCAR:
naniar::mcar_test(housing.df)
# replace the missing values using the median of the remaining values.
# use median() with na.rm = TRUE to ignore missing values when computing the median.
housing.df[rows.to.missing,]$BEDROOMS <- median(housing.df$BEDROOMS, na.rm = TRUE)
summary(housing.df$BEDROOMS)
housing.df[rows.to.missing,]$BEDROOMS <- mean(housing.df$BEDROOMS, na.rm = TRUE)
summary(housing.df$BEDROOMS)
# Standardize data ----
# Does it affect the shape?
plot(density(housing.df[,1]))
plot(density(scale(housing.df[,1])))
# No, just the SCALE.
bedrooms_scaled <- scale(housing.df$BEDROOMS)
bedrooms_minmaxscales <- (housing.df$BEDROOMS - min(housing.df$BEDROOMS))/
(range(housing.df$BEDROOMS))
plot(density(bedrooms_zscaled))
# No, just the SCALE.
bedrooms_zscaled <- scale(housing.df$BEDROOMS)
bedrooms_minmaxscales <- (housing.df$BEDROOMS - min(housing.df$BEDROOMS))/
(range(housing.df$BEDROOMS))
plot(density(bedrooms_zscaled))
plot(density(bedrooms_minmaxscales))
lines(density(bedrooms_minmaxscales), col = "red")
plot(density(bedrooms_zscaled))
lines(density(bedrooms_minmaxscales), col = "red")
# The results are quite different, but serve the same purpose
mean(bedrooms_zscaled)
mean(bedrooms_minmaxscales)
range(housing.df$BEDROOMS)
max(housing.df$BEDROOMS)
min(housing.df$BEDROOMS)
# No, just the SCALE.
bedrooms_zscaled <- scale(housing.df$BEDROOMS)
bedrooms_minmaxscales <- (housing.df$BEDROOMS - min(housing.df$BEDROOMS))/
(max(housing.df$BEDROOMS) = min(housing.df$BEDROOMS))
# No, just the SCALE.
bedrooms_zscaled <- scale(housing.df$BEDROOMS)
bedrooms_minmaxscales <- (housing.df$BEDROOMS - min(housing.df$BEDROOMS))/
(max(housing.df$BEDROOMS) - min(housing.df$BEDROOMS))
plot(density(bedrooms_zscaled))
lines(density(bedrooms_minmaxscales), col = "red")
plot(density(bedrooms_zscaled), ylim = c(0,3))
lines(density(bedrooms_minmaxscales), col = "red")
plot(density(bedrooms_zscaled), ylim = c(0,5))
lines(density(bedrooms_minmaxscales), col = "red")
plot(density(bedrooms_zscaled), ylim = c(0,10))
lines(density(bedrooms_minmaxscales), col = "red")
plot(density(bedrooms_zscaled), ylim = c(0,5))
lines(density(bedrooms_minmaxscales), col = "red")
library(dplyr)
# Simple strategies for dimension reduction
boston.housing.df <- read.csv("BostonHousing.csv", header = TRUE)
head(boston.housing.df, 9)
summary(boston.housing.df)
# Now we can use dplyr and magrittr to create pivot tables:
housing.df %>%
group_by(ROOMS, REMODEL) %>%
summarize(count_by_year = n())
# Now we can use dplyr and magrittr to create pivot tables:
housing.df %>%
group_by(ROOMS, REMODEL) %>%
summarize(count = n(),
Value = mean(TOTAL.VALUE))
# Now we can use dplyr and magrittr to create pivot tables:
housing.df %>%
group_by(ROOMS, REMODEL) %>%
summarize(count = n(),
Value = mean(TOTAL.VALUE),
Risk = sd(TOTAL.VALUE))
# Now we can use dplyr and magrittr to create pivot tables:
housing.df %>%
group_by(ROOMS, REMODEL) %>%
summarize(count = n(),
Value = mean(TOTAL.VALUE),
Risk = sd(TOTAL.VALUE))
nick_func(boston.housing.df)
# Or we can use dplyr and magrittr to create pivot tables:
housing.df %>%
group_by(ROOMS, REMODEL) %>%
summarize(count = n(),
Value = mean(TOTAL.VALUE),
Risk = sd(TOTAL.VALUE))
# Principal Components Analysis ----
decathlon <- read.csv(file = "decathlon_data.txt", sep="\t", header = TRUE)
round(cor(decathlon),2)
heatmap(cor(decathlon))
correlates <- decathlon[,c("X100m", "X110h", "X400m","X1500m")]
decathlon_eigen <- eigen(cor(correlates))
decathlon_eigen$values
sum(decathlon_eigen$values)
sqrt(2.429)
decathlon_eigen$values / sum(decathlon_eigen$values)
eigen_vector <- decathlon_eigen$vectors
eigen_vector
rownames(eigen_vector) <- colnames(correlates)
eigen_vector
rownames(eigen_vector) <- colnames(correlates)
eigen_vector
dec_pca <- prcomp(decathlon, scale. = TRUE)
dec_pca$sdev
dec_pca$rotation
screeplot(dec_pca, type="lines")
abline(h = 1, lty = 4,lwd = 4, col = "green")
dec_pca$x
round(dec_pca$rotation, 2)
summary(dec_pca)
dec_scores <- dec_pca$x
plot(dec_scores, pch=19)
cor(dec_scores)
decathlon$PC1 <- dec_scores[, "PC1"]
decathlon$PC2 <- dec_scores[, "PC2"]
decathlon$PC3 <- dec_scores[, "PC3"]
decathlon$PC4 <- dec_scores[, "PC4"]
cor(dec_scores)
cor(dec_scores)
round(cor(dec_scores),2)
decathlon$PC1 <- dec_scores[, "PC1"]
decathlon$PC2 <- dec_scores[, "PC2"]
decathlon$PC3 <- dec_scores[, "PC3"]
decathlon$PC4 <- dec_scores[, "PC4"]
